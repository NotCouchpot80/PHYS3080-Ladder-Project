{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4aa5fdd-c9d6-436c-bba9-705b05e2ad19",
   "metadata": {},
   "source": [
    "## Project setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a7e5c88-13d2-4504-b301-d967d74e4647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table\n",
    "import glob\n",
    "import warnings\n",
    "from sklearn import mixture\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from sklearn.utils.fixes import parse_version\n",
    "\n",
    "# \n",
    "# configure notebook for plotting\n",
    "%pylab inline --no-import-all \n",
    "mpl.style.use('seaborn-colorblind') # colourblind-friendly colour scheme\n",
    "colours = mpl.rcParams['axes.prop_cycle'].by_key()['color'] # allows access to colours\n",
    "# subsequent lines default plot settings\n",
    "matplotlib.rcParams['image.origin'] = 'lower'\n",
    "matplotlib.rcParams['figure.figsize']=(20,5)  \n",
    "matplotlib.rcParams['font.size']=16    \n",
    "matplotlib.rcParams['savefig.dpi']= 300   \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# functions\n",
    "def in_hull(p, hull):\n",
    "    # \"\"\"\n",
    "    # code from https://stackoverflow.com/questions/16750618/whats-an-efficient-way-to-find-if-a-point-lies-in-the-convex-hull-of-a-point-cl, by user Juh_\n",
    "    # Test if points in `p` are in `hull`\n",
    "\n",
    "    # `p` should be a `NxK` coordinates of `N` points in `K` dimensions\n",
    "    # `hull` is either a scipy.spatial.Delaunay object or the `MxK` array of the \n",
    "    # coordinates of `M` points in `K`dimensions for which Delaunay triangulation\n",
    "    # will be computed\n",
    "    # \"\"\"\n",
    "    if not isinstance(hull,Delaunay):\n",
    "        hull = Delaunay(hull)\n",
    "\n",
    "    return hull.find_simplex(p)>=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9acef6-8e6b-417c-8526-2b7749f2c89e",
   "metadata": {},
   "source": [
    "## Initial data entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "650c9736-959c-42ec-bb05-255d588cc58c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import data from Data directory\n",
    "allPointsFiles = glob.glob('../Data/*/*/points.txt')\n",
    "allFuzzyFiles = glob.glob('../Data/*/*/fuzzy.txt')\n",
    "allVaryingPointFiles = glob.glob('../Data/*/*/P*.csv')\n",
    "allXrayFiles = glob.glob('../Data/XrayFlash.txt')\n",
    "\n",
    "# initiate initial variables\n",
    "farPoints = []\n",
    "midPoints = []\n",
    "closePoints = []\n",
    "allPoints = []\n",
    "variablePoints = []\n",
    "xRayPoints = []\n",
    "fuzzies = []\n",
    "name2ID = []\n",
    "# initial loading and sorting\n",
    "# points (row = [name, x, y, distance, HRx, HRy, RV])\n",
    "\n",
    "# initiate parameters\n",
    "upperParallaxLimit = 0.006\n",
    "lowerParallaxLimit = 0.005\n",
    "ID=100000\n",
    "# sort the points\n",
    "for j, pointsFile in enumerate(allPointsFiles):\n",
    "    try:\n",
    "        this = Table.read(pointsFile,format='ascii')\n",
    "        thispar = this['par']\n",
    "        thism0, thism1, thism2 = (np.log10(this['flux1']), \n",
    "                                  np.log10(this['flux2']), \n",
    "                                  np.log10(this['flux3']))\n",
    "        thiscolour = thism2-thism0\n",
    "        # transform coords onto \"sky net\" based on file path and store in numpy array          \n",
    "        if pointsFile.rfind('Up')!=-1:\n",
    "            points = np.array([this['name'], this['y'], -this['x']+90, thispar, thiscolour, thism1, this['rv']]).T.tolist()\n",
    "        elif pointsFile.rfind('Front')!=-1:\n",
    "            points = np.array([this['name'], this['y']-90, -this['x']+90, thispar, thiscolour, thism1, this['rv']]).T.tolist()\n",
    "        elif pointsFile.rfind('Right')!=-1:\n",
    "            points = np.array([this['name'], this['x'], this['y'], thispar, thiscolour, thism1, this['rv']]).T.tolist()\n",
    "        elif pointsFile.rfind('Back')!=-1:\n",
    "            points = np.array([this['name'], this['x']+90, this['y'], thispar, thiscolour, thism1, this['rv']]).T.tolist()\n",
    "        elif pointsFile.rfind('Left')!=-1:\n",
    "            points = np.array([this['name'], this['y']-90, -this['x']+180, thispar, thiscolour, thism1, this['rv']]).T.tolist()\n",
    "        elif pointsFile.rfind('Down')!=-1:\n",
    "            points = np.array([this['name'], this['y'], -this['x']-90, thispar, thiscolour, thism1, this['rv']]).T.tolist()\n",
    "            \n",
    "        # sort into close and far\n",
    "        for point in points:\n",
    "            ID=ID+1\n",
    "            name2ID.append([point[0],ID])\n",
    "            point[0]=str(ID)\n",
    "            if float(point[3]) > upperParallaxLimit:\n",
    "                closePoints.append(point)\n",
    "            elif float(point[3]) <= lowerParallaxLimit:# value chosen to minimize clusters being assigned to mid distance\n",
    "                farPoints.append(point)   \n",
    "            else:\n",
    "                midPoints.append(point)  \n",
    "    except Exception as e:\n",
    "        print('Failed point sorting: '+ str(e))\n",
    "        pass\n",
    "closePoints=np.array(closePoints).astype(np.float)\n",
    "midPoints=np.array(midPoints).astype(np.float).astype(np.float)\n",
    "farPoints=np.array(farPoints).astype(np.float)\n",
    "allPoints=np.concatenate((closePoints, midPoints, farPoints),axis=0).astype(np.float)\n",
    "name2ID=np.array(name2ID)\n",
    "# fuzzies (row = [name, x, y, flux1, flux2, flux3, width, RV])\n",
    "for j, fuzzyFile in enumerate(allFuzzyFiles):\n",
    "    fuzzy=[]\n",
    "    try:\n",
    "        this = Table.read(fuzzyFile,format='ascii')\n",
    "        # transform coords onto \"sky net\" based on file path and store in numpy array          \n",
    "        if pointsFile.rfind('Up')!=-1:\n",
    "            fuzzy = np.array([this['name'], this['y'], -this['x']+90,this['flux1'], this['flux2'],this['flux3'], this['width'], this['rv']]).T.tolist()\n",
    "        elif pointsFile.rfind('Front')!=-1:\n",
    "            fuzzy = np.array([this['name'], this['y']-90, -this['x']+90, this['flux1'], this['flux2'],this['flux3'], this['width'], this['rv']]).T.tolist()\n",
    "        elif pointsFile.rfind('Right')!=-1:\n",
    "            fuzzy = np.array([this['name'], this['x'], this['y'], this['flux1'], this['flux2'],this['flux3'], this['width'], this['rv']]).T.tolist()\n",
    "        elif pointsFile.rfind('Back')!=-1:\n",
    "            fuzzy = np.array([this['name'], this['x']+90, this['y'], this['flux1'], this['flux2'],this['flux3'], this['width'], this['rv']]).T.tolist()\n",
    "        elif pointsFile.rfind('Left')!=-1:\n",
    "            fuzzy = np.array([this['name'], this['y']-90, -this['x']+180, this['flux1'], this['flux2'],this['flux3'], this['width'], this['rv']]).T.tolist()\n",
    "        elif pointsFile.rfind('Down')!=-1:\n",
    "            fuzzy = np.array([this['name'], this['y'], -this['x']-90, this['flux1'], this['flux2'],this['flux3'], this['width'], this['rv']]).T.tolist()\n",
    "    except:\n",
    "        pass\n",
    "    fuzzies.append(fuzzy)\n",
    "fuzzies = np.array(fuzzies).astype(np.float)\n",
    "\n",
    "# Xray flashes (row = [x, y, luminosity])\n",
    "for j, XrayFiles in enumerate(allXrayFiles):\n",
    "    Xrays = []\n",
    "    try:\n",
    "        this = Table.read(XrayFiles,format='ascii')\n",
    "        for line in this:\n",
    "            # transform coords onto \"sky net\" based on file path and store in numpy array          \n",
    "            if line['Camera']==('Up'):\n",
    "                Xrays = np.array([line['y'], -line['x']+90, line['mag']]).T.tolist()\n",
    "            elif line['Camera']==('Front'):\n",
    "                Xrays = np.array([ line['y']-90, -line['x']+90, line['mag']]).T.tolist()\n",
    "            elif line['Camera']==('Right'):\n",
    "                Xrays = np.array([ line['x'], line['y'], line['mag']]).T.tolist()\n",
    "            elif line['Camera']==('Back'):\n",
    "                Xrays = np.array([line['x']+90, line['y'], line['mag']]).T.tolist()\n",
    "            elif line['Camera']==('Left'):\n",
    "                Xrays = np.array([ line['y']-90, -line['x']+180, line['mag']]).T.tolist()\n",
    "            elif line['Camera']==('Down'):\n",
    "                Xrays = np.array([ line['y'], -line['x']-90, line['mag']]).T.tolist()\n",
    "\n",
    "            xRayPoints.append(Xrays)\n",
    "    except Exception as e:\n",
    "        logger.error('Failed: '+ str(e))\n",
    "        pass\n",
    "xRayflashes=np.array(xRayPoints).astype(np.float)\n",
    "\n",
    "# Variable points (row = [name, x, y, dist, HRx, HRy, abs mag, RV, variable data])\n",
    "for j, varsFile in enumerate(allVaryingPointFiles):\n",
    "    \n",
    "    try:\n",
    "        thisVar = np.array(Table.read(varsFile,format='ascii'))\n",
    "        name = varsFile[-10:-4]\n",
    "        pointID=name2ID[name2ID[:,0]==name,1][0]\n",
    "        basicData=allPoints[(allPoints[:,0]==pointID.astype(np.float)),:]\n",
    "        variablePoint=np.array([basicData[0,0],basicData[0,1],basicData[0,2],basicData[0,3],basicData[0,4],basicData[0,5],basicData[0,6],thisVar])\n",
    "        variablePoints.append(variablePoint)\n",
    "    except Exception as e:\n",
    "        print('Failed: '+ str(e))\n",
    "        print(varsFile[-10:-4])\n",
    "        pass\n",
    "variablePoints=np.array(variablePoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2c4f73-8cc5-43b5-9802-98998c25f7cf",
   "metadata": {},
   "source": [
    "## Calculate HRy flattener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e1ee0f2-0a0d-4b6a-aed4-a248280d3c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transform HRy\n",
    "absMag = closePoints[:,5].astype(np.float) + 2*np.log10(1/closePoints[:,3].astype(np.float))\n",
    "BenchMark = np.array([closePoints[:,4].astype(np.float), absMag]).T\n",
    "branches=[]\n",
    "# Identify benchmark main seqence cluster with BGMM\n",
    "branchCount = 4   # clusterCount\n",
    "tol=0.0005\n",
    "countStep = 5\n",
    "CountTrials = 10\n",
    "branchesModel = (mixture.BayesianGaussianMixture(\n",
    "                tol=tol,\n",
    "                n_components=branchCount,\n",
    "                covariance_type=\"full\",\n",
    "                n_init = CountTrials\n",
    "                )).fit(BenchMark)    \n",
    "branchShapes = branchesModel.predict(BenchMark)\n",
    "# Collate branch points\n",
    "for i, (weights) in enumerate(branchesModel.weights_):\n",
    "    if not np.any(branchShapes == i) or weights<(0.01/branchCount):\n",
    "        continue        \n",
    "    branches.append(BenchMark[branchShapes == i, :])\n",
    "## get Main sequence to fit polynomial\n",
    "clusterSize=0\n",
    "i=0\n",
    "MSindex=0\n",
    "for branch in branches:\n",
    "    if len(branch)>clusterSize:\n",
    "        clusterSize=len(branch)\n",
    "        MSindex=i\n",
    "    i=i+1\n",
    "mainSequenceBenchmark=branches[MSindex]\n",
    "MSFit4=np.poly1d(np.polyfit(mainSequenceBenchmark[:,0],mainSequenceBenchmark[:,1],4))\n",
    "MSFit1=np.poly1d(np.polyfit(mainSequenceBenchmark[:,0],mainSequenceBenchmark[:,1],1))\n",
    "# Transform all close points HR values\n",
    "BenchMarktHRx=BenchMark[:,0]\n",
    "BenchMarktHRy=BenchMark[:,1]-np.power(BenchMark[:,0],4)*MSFit4.c[0]-np.power(BenchMark[:,0],3)*MSFit4.c[1]-np.power(BenchMark[:,0],2)*MSFit4.c[2]-BenchMark[:,0]*MSFit4.c[3]-MSFit4.c[4]\n",
    "linearBenchMarktHRy=BenchMark[:,1]-BenchMark[:,0]*MSFit1.c[0]-MSFit1.c[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8cc228-15fd-4002-af88-12f437322c1b",
   "metadata": {},
   "source": [
    "## breakdown point clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae761a9-f681-4d08-8c92-2625261fe0e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_13808/454161923.py, line 96)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\mogle\\AppData\\Local\\Temp/ipykernel_13808/454161923.py\"\u001b[1;36m, line \u001b[1;32m96\u001b[0m\n\u001b[1;33m    continue\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Initiate output arrays\n",
    "protoClusters = []\n",
    "subClusters = []    #row = [ID, x, y, HRx, tHRy, rv]\n",
    "clusters = []\n",
    "# initiate input arrays\n",
    "# X row = [ID, x, y, HRx, HRy, rv]\n",
    "unassigned = []\n",
    "# get protoClusters\n",
    "X=np.concatenate([farPoints[:,[0,1,2,4,5,6]], midPoints[:,[0,1,2,4,5,6]]]).astype(np.float)\n",
    "numberOfClusters = 1\n",
    "NOCinc = 1\n",
    "trials = 1\n",
    "tol=0.001\n",
    "WCP = 1\n",
    "MPR = 1\n",
    "minClusterSize=4\n",
    "features=[1,2,5]\n",
    "ProtoClustersModel = (mixture.BayesianGaussianMixture(\n",
    "                tol=tol,\n",
    "                weight_concentration_prior=WCP,\n",
    "                mean_precision_prior=MPR,\n",
    "                n_components=numberOfClusters,\n",
    "                covariance_type=\"full\",\n",
    "                n_init = trials\n",
    "                )).fit(X[:,features])\n",
    "while min(ProtoClustersModel.weights_)>(0.01/numberOfClusters):\n",
    "    \n",
    "    numberOfClusters=numberOfClusters+NOCinc\n",
    "    \n",
    "    ProtoClustersModel = (mixture.BayesianGaussianMixture(\n",
    "                    weight_concentration_prior=WCP,\n",
    "                    mean_precision_prior=MPR,\n",
    "                    tol=tol,\n",
    "                    n_components=numberOfClusters,\n",
    "                    covariance_type=\"full\",\n",
    "                    n_init = trials\n",
    "                    )).fit(X[:,features])\n",
    "ProtoClustersModel = (mixture.BayesianGaussianMixture(\n",
    "                tol=tol,\n",
    "                weight_concentration_prior=WCP,\n",
    "                mean_precision_prior=MPR,\n",
    "                n_components=numberOfClusters-1,\n",
    "                covariance_type=\"full\",\n",
    "                n_init = trials\n",
    "                )).fit(X[:,features])\n",
    "protoClusterShapes = ProtoClustersModel.predict(X[:,features])\n",
    "for i, weights in enumerate(ProtoClustersModel.weights_):\n",
    "    \n",
    "    if not np.any(protoClusterShapes == i) or weights<(0.01/numberOfClusters) or len(X[protoClusterShapes == i, :])<minClusterSize:\n",
    "        print('rejected: ', str(len(X[protoClusterShapes == i, :])))\n",
    "        try:\n",
    "            unassigned.append(X[protoClusterShapes == i, :].tolist()[0])\n",
    "            continue\n",
    "        except:\n",
    "            continue\n",
    "    protoClusters.append(X[protoClusterShapes == i, :])\n",
    "totalPointsP = 0\n",
    "\n",
    "# get subClusters\n",
    "for protoCluster in protoClusters:\n",
    "    # parameters\n",
    "    tol=0.001\n",
    "    numberOfSubClusterCount = 3   #initial clusterCount\n",
    "    minSubclusterSize = 20\n",
    "    trials = 5\n",
    "    features=[1,2,5]\n",
    "    subClustersModel = (mixture.BayesianGaussianMixture(\n",
    "                        tol=tol,\n",
    "                        n_components=numberOfSubClusterCount,\n",
    "                        covariance_type=\"full\",\n",
    "                        )).fit(protoCluster[:,features])\n",
    "    while min(subClustersModel.weights_)>(0.1/numberOfSubClusterCount):\n",
    "        numberOfSubClusterCount = numberOfSubClusterCount + 1\n",
    "        subClustersModel = (mixture.BayesianGaussianMixture(\n",
    "                            n_init = trials,\n",
    "                            tol=tol,\n",
    "                            n_components=numberOfSubClusterCount,\n",
    "                            covariance_type=\"full\",\n",
    "                            )).fit(protoCluster[:,features])\n",
    "    subClustersModel = (mixture.BayesianGaussianMixture(\n",
    "                        n_init = trials,\n",
    "                        tol=tol,\n",
    "                        n_components=numberOfSubClusterCount-1,\n",
    "                        covariance_type=\"full\",\n",
    "                        )).fit(protoCluster[:,features])\n",
    "    subClusterShapes = subClustersModel.predict(protoCluster[:,features])\n",
    "# collate subclusters\n",
    "    for i, (weights) in enumerate(subClustersModel.weights_):\n",
    "        if not np.any(subClusterShapes == i) or len(protoCluster[subClusterShapes == i, :])<minSubclusterSize:\n",
    "            try:\n",
    "                test = protoCluster[subClusterShapes == i, :].tolist()[:][:]\n",
    "                unassigned.extend(protoCluster[subClusterShapes == i, :].tolist()[:][:])\n",
    "                # print('unassigned 1')\n",
    "            except:\n",
    "                print('')\n",
    "            continue\n",
    "        temp=protoCluster[subClusterShapes == i, :]\n",
    "        subClusters.append(np.array([temp[:,0],temp[:,1],temp[:,2],temp[:,3],temp[:,4], temp[:,5]]).T)\n",
    "subClusters=np.array(subClusters)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d466cf-f20e-49d4-a2fa-d344c26a0ab7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Rebuild points clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc95b809-2072-4c75-b990-aab331e6783d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d, Delaunay\n",
    "from scipy.interpolate import griddata\n",
    "# Calculate prereq cluster data (boundary, Main sequence HRy, RV profile)\n",
    "# \n",
    "        # tHRy = temp[:,4]-np.square(temp[:,3])*MSFit.c[0]-temp[:,3]*MSFit.c[1]-MSFit.c[2]\n",
    "\n",
    "subClusterMS = []\n",
    "boundaries = []\n",
    "RVP = []\n",
    "for subCluster in subClusters:\n",
    "    Xms = np.array([subCluster[:,3], subCluster[:,4]-np.power(subCluster[:,3],4)*MSFit4.c[0]-np.power(subCluster[:,3],3)*MSFit4.c[1]-np.power(subCluster[:,3],2)*MSFit4.c[2]-subCluster[:,3]*MSFit4.c[3]-MSFit4.c[4]]).T\n",
    "    ltHRy = np.array([subCluster[:,3],subCluster[:,4]-subCluster[:,3]*MSFit1.c[0]-MSFit1.c[1]]).T\n",
    "\n",
    "    branches=[]\n",
    "    # Identify benchmark main seqence cluster with BGMM\n",
    "    branchCount = 3   # clusterCount\n",
    "    countStep = 5\n",
    "    CountTrials = 3\n",
    "    branchesModel = (mixture.BayesianGaussianMixture(\n",
    "                    n_components=branchCount,\n",
    "                    covariance_type=\"full\",\n",
    "                    n_init = CountTrials\n",
    "                    )).fit(ltHRy)    \n",
    "    branchShapes = branchesModel.predict(ltHRy)\n",
    "    # Collate branch points\n",
    "    for i, (weights) in enumerate(branchesModel.weights_):\n",
    "        if not np.any(branchShapes == i) or weights<(0.01/branchCount):\n",
    "            continue        \n",
    "        branches.append(Xms[branchShapes == i, :])\n",
    "    ## get Main sequence to fit polynomial\n",
    "    clusterSize=0\n",
    "    i=0\n",
    "    MSindex=0\n",
    "    for branch in branches:\n",
    "        if len(branch)>clusterSize:\n",
    "            clusterSize=len(branch)\n",
    "            MSindex=i\n",
    "        i=i+1\n",
    "    subClusterMS.append(branches[MSindex][branches[MSindex][:,0]>-0.6,:])\n",
    "    \n",
    "    \n",
    "    boundary=subCluster[:,[1,2]]\n",
    "    boundaries.append(Delaunay(boundary))   \n",
    "    # get RVfit\n",
    "    xi, yi = np.meshgrid(np.linspace(-1,1,100),np.linspace(-1,1,100))\n",
    "    RVP.append(griddata(subCluster[:,[1,2]], subCluster[:,5], (xi,yi), method='cubic'))\n",
    "    \n",
    "boundaries = np.array(boundaries) \n",
    "xi, yi = np.meshgrid(np.linspace(-1,1,100),np.linspace(-1,1,100))   \n",
    "clusters = subClusters\n",
    "clusterMS = np.array(subClusterMS)\n",
    "exists = np.ones(len(clusters)).astype(int)\n",
    "oldExistSum=np.infty\n",
    "while np.sum(exists)<oldExistSum:\n",
    "    oldExistSum=np.sum(exists)\n",
    "    exists = np.ones(len(clusters)).astype(int)\n",
    "    for h, hostCluster in enumerate(clusters):\n",
    "        # get cluster boundary\n",
    "        if exists[h]==1:\n",
    "            for i, otherCluster in enumerate(clusters):\n",
    "                overlap = sum(abs(in_hull(otherCluster[:,[1,2]], boundaries[h])))\n",
    "                difMeans = np.sqrt((np.mean(otherCluster[:,1])-np.mean(hostCluster[:,1]))**2 + (np.mean(otherCluster[:,2])-np.mean(hostCluster[:,2]))**2)\n",
    "                maxRH = max(np.sqrt((hostCluster[:,1]-np.mean(hostCluster[:,1]))**2 + (hostCluster[:,2]-np.mean(hostCluster[:,2]))**2))\n",
    "                maxRO = max(np.sqrt((otherCluster[:,1]-np.mean(otherCluster[:,1]))**2 + (otherCluster[:,2]-np.mean(otherCluster[:,2]))**2))\n",
    "                maxR =maxRH + maxRO\n",
    "                if (exists[i]==1):\n",
    "                    print(\"Host: \", h, ', index: ', i, 'overlap: ', overlap)                                         # only use existing clusters\n",
    "                    if (i != h\n",
    "                    and (overlap>0                                        # overlap checker\n",
    "                    or difMeans<maxR)\n",
    "                       ):\n",
    "                            tTest=sp.stats.ttest_ind(clusterMS[h][:,1], clusterMS[i][:,1], axis=0, equal_var=False)\n",
    "                            print('        ',tTest)\n",
    "                            if tTest[1]>0.05:\n",
    "                                print('        ', h, ' match with ', i)\n",
    "\n",
    "                                clusters[h] = np.append(clusters[h],clusters[i],axis=0)      # Update host\n",
    "                                boundaries[h] = Delaunay(clusters[h][:,[1,2]])\n",
    "                                clusterMS[h] =  np.append(clusterMS[h],clusterMS[i],axis=0) \n",
    "                                # RVP[h] = sp.griddata(clusters[:,[1,2]], clusters[:,5], (xi,yi), method='cubic')\n",
    "                                exists[i] = 0\n",
    "    clusters=clusters[exists == 1]\n",
    "    boundaries = boundaries[exists == 1]    \n",
    "    clusterMS = clusterMS[exists == 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f4eb2a-9a08-4934-97d5-07cad3976f09",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee072a-29a2-4262-9080-594d3b55a9e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot benchmark\n",
    "BMplot = mpl.pyplot.figure()\n",
    "### Sky map cluster plot\n",
    "ax1 = BMplot.add_subplot(1, 2, 1)\n",
    "plt.grid()\n",
    "mpl.pyplot.scatter(BenchMarktHRx, BenchMark[:,1])\n",
    "ax1 = BMplot.add_subplot(1, 2, 2)\n",
    "plt.grid()\n",
    "mpl.pyplot.scatter(BenchMarktHRx, BenchMarktHRy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e408462b-01c8-4454-a793-5892793293d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot subClusters\n",
    "subClusterPlots=[]\n",
    "for i, subCluster in enumerate(subClusters):\n",
    "    subClusterPlots.append(mpl.pyplot.figure())\n",
    "    ### Sky map cluster plot\n",
    "    ax1 = subClusterPlots[-1].add_subplot(1, 3, 1)\n",
    "    plt.grid()\n",
    "    mpl.pyplot.scatter(subCluster[:,1], subCluster[:,2], c= subCluster[:,5], cmap= 'bwr', marker ='x')\n",
    "    ### HR diagram cluster plot\n",
    "    ax2 = subClusterPlots[-1].add_subplot(1, 3, 2)\n",
    "    plt.grid()\n",
    "    mpl.pyplot.scatter(subCluster[:,3],subCluster[:,4], marker = 'x', color='blue')\n",
    " \n",
    "    ax3 = subClusterPlots[-1].add_subplot(1, 3, 3)\n",
    "    \n",
    "    mpl.pyplot.scatter(subClusterMS[i][:,0],subClusterMS[i][:,1], marker = '+', color='green')\n",
    "    # ax3.fill(X_plot, subCluster[2], fc=\"#AAAAFF\")\n",
    "    # ax3.set_xlim(min(farPoints_floats[:,5]),2)\n",
    "    ax3.set_ylim(-10,-2)\n",
    "    plt.grid()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac58b4-9844-429a-8d7e-d629b8840a13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot clusters\n",
    "clusterPlots=[]\n",
    "for i, cluster in enumerate(clusters):\n",
    "    clusterPlots.append(mpl.pyplot.figure())\n",
    "    ### Sky map cluster plot\n",
    "    ax1 = clusterPlots[-1].add_subplot(1, 3, 1)\n",
    "    plt.grid()\n",
    "    mpl.pyplot.scatter(cluster[:,1], cluster[:,2], c= cluster[:,5], cmap= 'bwr', marker ='x')\n",
    "    ### HR diagram cluster plot\n",
    "    ax2 = clusterPlots[-1].add_subplot(1, 3, 2)\n",
    "    plt.grid()\n",
    "    mpl.pyplot.scatter(cluster[:,3],cluster[:,4], marker = 'x', color='blue')\n",
    "    ax3 = clusterPlots[-1].add_subplot(1, 3, 3)\n",
    "    mpl.pyplot.scatter(clusterMS[i][:,0],clusterMS[i][:,1], marker = '+', color='green')\n",
    "    ax3.set_ylim(-10,-2)\n",
    "    plt.grid()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88965d-b088-4d43-b3aa-fab2b6401bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalPointsSC = 0\n",
    "totalPointsC = 0\n",
    "totalPointsP = 0\n",
    "unassigned = unassigned\n",
    "\n",
    "totalPointsP = 0\n",
    "for protoCluster in protoClusters:\n",
    "    totalPointsP = totalPointsP + len(protoCluster)\n",
    "    \n",
    "totalPointsSC = 0    \n",
    "for subCluster in subClusters:\n",
    "    totalPointsSC = totalPointsSC + len(subCluster)\n",
    "    \n",
    "totalPointsC = 0\n",
    "for cluster in clusters:\n",
    "    totalPointsC = totalPointsC + len(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb09632-bccc-4d76-82ba-cb6f0f56f8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf5531-9b82-4cbf-b9e3-d3fe43ecc0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cc61eb-e154-495a-8730-75291fcaf8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
